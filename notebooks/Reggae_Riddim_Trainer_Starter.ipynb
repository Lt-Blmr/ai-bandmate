{"cells":[{"cell_type":"code","source":["# SYSTEM PREP\n","!pip install -q yt-dlp librosa gcsfs google-cloud-storage torchaudio\n","!pip install -q demucs==4.0.0 pretty_midi\n","\n","# Authenticate if running in Colab\n","from google.colab import auth\n","auth.authenticate_user()\n"],"metadata":{"id":"BB9vupIk4pb6","executionInfo":{"status":"ok","timestamp":1743275486003,"user_tz":420,"elapsed":16060,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"BB9vupIk4pb6","execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["üí¨ QC Note: Clear and focused. Consider encapsulating environment setup into a script for reproducibility."],"metadata":{"id":"72tuH3Wi8OYL"},"id":"72tuH3Wi8OYL"},{"cell_type":"code","source":["import os\n","import gcsfs\n","from google.cloud import storage\n","\n","# CONFIG ‚Äì customize this for your project\n","PROJECT_ID = \"rootz-engine\"\n","INPUT_BUCKET = \"rootz-engine-input\"\n","OUTPUT_BUCKET = \"rootz-engine-output\"\n","TRAINING_BUCKET = \"rootz-engine-training\"\n","\n","os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n","\n","# GCS setup\n","fs = gcsfs.GCSFileSystem(project=PROJECT_ID)\n","storage_client = storage.Client()\n","input_bucket = storage_client.bucket(INPUT_BUCKET)\n","output_bucket = storage_client.bucket(OUTPUT_BUCKET)\n","training_bucket = storage_client.bucket(TRAINING_BUCKET)\n","\n","# Local dirs\n","TEMP_DIR = \"/content/temp\"\n","DOWNLOAD_DIR = \"/content/mp3\"\n","os.makedirs(TEMP_DIR, exist_ok=True)\n","os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n","\n","print(\"‚úÖ GCS ready, local directories created.\")\n"],"metadata":{"id":"t1iVs3Jh45QB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743275487027,"user_tz":420,"elapsed":1021,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}},"outputId":"51c77340-dfaf-4411-849f-3a049ea2c240"},"id":"t1iVs3Jh45QB","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ GCS ready, local directories created.\n"]}]},{"cell_type":"markdown","source":["üí¨ QC Note: ‚úÖ Functional but must replace placeholder PROJECT_ID. Suggest moving config to .env or a JSON if this will scale."],"metadata":{"id":"08of9RaA8c12"},"id":"08of9RaA8c12"},{"cell_type":"code","source":["def download_mp3s():\n","    blobs = input_bucket.list_blobs()\n","    for blob in blobs:\n","        if blob.name.endswith(\".mp3\"):\n","            destination = os.path.join(DOWNLOAD_DIR, os.path.basename(blob.name))\n","            if not os.path.exists(destination):\n","                print(f\"‚¨áÔ∏è Downloading {blob.name} ‚Üí {destination}\")\n","                blob.download_to_filename(destination)\n","            else:\n","                print(f\"‚è≠Ô∏è Already downloaded: {destination}\")\n","\n","download_mp3s()\n"],"metadata":{"id":"dEd8H-hw3cln","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743275487460,"user_tz":420,"elapsed":434,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}},"outputId":"2e33a07c-420a-4fd2-c4e6-8aa5d23946bd"},"id":"dEd8H-hw3cln","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚è≠Ô∏è Already downloaded: /content/mp3/007 [2S_wq99sbWM].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/12_ Don Carlos - Mr Sun [quvsj04WexE].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/400 Years (1970) - Bob Marley & The Wailers [gCD6AG2yi5A].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/African Herbsman (Dub Version) [3XVdwSntbPU].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/All In One - Original [SXyf4IaBdLA].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/BOB MARLEY THREE LITTLE BIRDS [zaGUr6wzyT8].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Bam Bam - Sister Nancy [OcaPu9JPenU].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Bam Bam [BGM0v44Yszk].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Barrington Levy - Be Strong [UUx1kXGqcvo].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Barrington Levy - Black Roses [OdhEAl_sI1A].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Barrington Levy - Murderer [W9mvTNh-plY].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Barrington Levy--Oh Jah,Can_t You See [ZfN5tTrRi6E].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Battle Axe (Small Axe Version) [ewYvV1Oh5gk].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Black Uhuru - Guess whos coming to dinner [KWEGXb2juvM].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Bob - Rock To The Rock - 1973, from 1968 recordings [kHBEuRUoX7A].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Brain Washing (Dub Version) [09kEWNIvbp8].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Brand New Second Hand (Alternate Version) [cW2Hn64Tgxw].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Brand New Second Hand (Dub Version) [mpZJxjwPudI].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Cali P. - Herbalist [XqHV6cX7gY4].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Chaka Demus & Pliers - Tease Me (Official Music Video) [ixZjoc_jlmQ].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Chezidek - All My Life (Official Video) [O3cPx6TZFSo].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Corner Stone (1970) - Bob Marley & The Wailers [mUswekQOChg].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Corner Stone (Dub Version) [YMvO8UydSOg].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Culture - why am i a rastamanÔºü [YSzXRgvqkps].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Cutty Ranks- Limb By Limb [tPeCHvAJCEQ].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Damian Marley - Welcome To Jamrock [xlCmQcRPtRg].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Don_t Rock My Boat (Dub Version) [jeEosGojnaU].mp3\n","‚è≠Ô∏è Already downloaded: /content/mp3/Don‚Äôt Rock My Boat (Alternate Mix 2) [PxrENeWCfkU].mp3\n"]}]},{"cell_type":"code","source":["# üî¢ Cell 4 ‚Äì Separate Stems Using Demucs (patched to use full path)\n","import torchaudio\n","import torch\n","import soundfile as sf\n","from demucs.pretrained import get_model\n","from demucs.apply import apply_model\n","\n","print(\"üéõÔ∏è Loading Demucs model...\")\n","model = get_model(\"htdemucs\")\n","model.cpu().eval()\n","\n","def separate_stems(mp3_path):\n","    if not os.path.exists(mp3_path):\n","        raise FileNotFoundError(f\"üéß MP3 file not found: {mp3_path}\")\n","\n","    filename = os.path.basename(mp3_path)\n","    song_name = os.path.splitext(filename)[0]\n","    stem_dir = os.path.join(STEMS_BASE_DIR, song_name)\n","\n","    if os.path.exists(os.path.join(stem_dir, \"bass.wav\")):\n","        print(f\"‚è≠Ô∏è Skipping {song_name}, stems already exist.\")\n","        return song_name, stem_dir\n","\n","    print(f\"üéöÔ∏è Separating stems for: {song_name}\")\n","    waveform, sr = torchaudio.load(mp3_path)\n","    waveform = torchaudio.functional.resample(waveform, sr, 44100)\n","\n","    with torch.no_grad():\n","        sources = apply_model(model, waveform[None], device=\"cpu\")[0]\n","\n","    os.makedirs(stem_dir, exist_ok=True)\n","    for source_name, audio in zip(model.sources, sources):\n","        out_path = os.path.join(stem_dir, f\"{source_name}.wav\")\n","        sf.write(out_path, audio.cpu().numpy().T, 44100)\n","        print(f\"‚úÖ Saved {source_name}.wav ‚Üí {out_path}\")\n","\n","    return song_name, stem_dir\n"],"metadata":{"id":"UCtArz0rCCnP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743275493830,"user_tz":420,"elapsed":6383,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}},"outputId":"babc2371-d381-47fc-8ecb-6801a0a13ced"},"id":"UCtArz0rCCnP","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["üéõÔ∏è Loading Demucs model...\n"]}]},{"cell_type":"markdown","source":["üîé Notes:\n","\n","    Accepts an .mp3 file path\n","\n","    Outputs all Demucs-separated stems into /content/stems/{SONG_NAME}/\n","\n","    Skips if already processed (idempotent)"],"metadata":{"id":"AnwRVuid8lJh"},"id":"AnwRVuid8lJh"},{"cell_type":"code","source":["# üî¢ Cell 5 ‚Äì Generate MIDI + Groove JSON\n","\n","import librosa\n","import pretty_midi\n","import json\n","import numpy as np\n","\n","def generate_midi_and_groove(stem_dir, song_name):\n","    bass_path = os.path.join(stem_dir, \"bass.wav\")\n","    if not os.path.exists(bass_path):\n","        raise FileNotFoundError(f\"Bass stem not found: {bass_path}\")\n","\n","    print(f\"üéº Generating MIDI + JSON for: {song_name}\")\n","\n","    # Load audio and extract rhythm\n","    y, sr = librosa.load(bass_path, sr=44100)\n","    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n","    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n","    onsets = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)\n","\n","    # Create MIDI\n","    midi_path = os.path.join(OUTPUT_DIR, f\"{song_name}.mid\")\n","    pm = pretty_midi.PrettyMIDI()\n","    instrument = pretty_midi.Instrument(program=34)  # Fingered bass\n","    for onset in onsets:\n","        start = onset / sr\n","        note = pretty_midi.Note(velocity=100, pitch=36, start=start, end=start + 0.2)\n","        instrument.notes.append(note)\n","    pm.instruments.append(instrument)\n","    pm.write(midi_path)\n","\n","    # Create Groove JSON\n","    json_path = os.path.join(OUTPUT_DIR, f\"{song_name}.json\")\n","    groove_data = {\n","        \"song\": song_name,\n","        \"tempo\": float(tempo),\n","        \"onsets\": onsets.tolist()\n","    }\n","    with open(json_path, \"w\") as f:\n","        json.dump(groove_data, f, indent=2)\n","\n","    print(f\"‚úÖ MIDI saved: {midi_path}\")\n","    print(f\"‚úÖ Groove JSON saved: {json_path}\")\n","    return midi_path, json_path\n"],"metadata":{"id":"hhM34v5tCIYw","executionInfo":{"status":"ok","timestamp":1743275493963,"user_tz":420,"elapsed":125,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"hhM34v5tCIYw","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["üîé Notes:\n","\n","    Reads the separated bass.wav file\n","\n","    Extracts:\n","\n","        Tempo\n","\n","        Onset locations\n","\n","    Outputs:\n","\n","        .mid file to /content/output/\n","\n","        .json groove map to /content/output/"],"metadata":{"id":"Wgq6AaaFEYzp"},"id":"Wgq6AaaFEYzp"},{"cell_type":"markdown","source":[],"metadata":{"id":"4h_ecxK-4tk4"},"id":"4h_ecxK-4tk4"},{"cell_type":"code","source":["# üî¢ Cell 6 ‚Äì Upload MIDI + Groove JSON to GCS (with logging + validation)\n","import logging\n","logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n","\n","def upload_outputs_to_gcs(midi_path, json_path, song_key, output_bucket):\n","    if not midi_path or not os.path.exists(midi_path):\n","        raise FileNotFoundError(f\"MIDI file not found: {midi_path}\")\n","    if not json_path or not os.path.exists(json_path):\n","        raise FileNotFoundError(f\"JSON file not found: {json_path}\")\n","    if not output_bucket:\n","        raise ValueError(\"Output bucket cannot be None.\")\n","\n","    try:\n","        midi_blob = output_bucket.blob(f\"midi/{song_key}.mid\")\n","        midi_blob.upload_from_filename(midi_path)\n","        logging.info(f\"Uploaded MIDI ‚Üí GCS: {midi_blob.name}\")\n","\n","        json_blob = output_bucket.blob(f\"groove/{song_key}.json\")\n","        json_blob.upload_from_filename(json_path)\n","        logging.info(f\"Uploaded Groove JSON ‚Üí GCS: {json_blob.name}\")\n","\n","    except Exception as e:\n","        logging.error(f\"Upload failed for {song_key}: {e}\")\n","        raise"],"metadata":{"id":"_bBmCcuL3mMc","executionInfo":{"status":"ok","timestamp":1743275493970,"user_tz":420,"elapsed":15,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"_bBmCcuL3mMc","execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U-8BJ3ZuCQ5j","executionInfo":{"status":"ok","timestamp":1743275493974,"user_tz":420,"elapsed":3,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"U-8BJ3ZuCQ5j","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["üîé Notes:\n","\n","    Uploads both files using a clean GCS path structure:\n","\n","        midi/{SONG_NAME}_bass.mid\n","\n","        groove/{SONG_NAME}_bass.json\n","\n","    Assumes output_bucket is already defined (‚úÖ done in Cell 2)"],"metadata":{"id":"LdOJlvFIEnf0"},"id":"LdOJlvFIEnf0"},{"cell_type":"markdown","source":["üí¨ QC Notes:\n","\n","    ‚úÖ Great structure and use of Demucs.\n","\n","    üí° Consider setting device=\"cuda\" if GPU available.\n","\n","    ‚ö†Ô∏è You may want to catch exceptions per file to avoid halting the batch.\n","\n","UPDATED 10:43 3/29    "],"metadata":{"id":"I56VjG5S8rqC"},"id":"I56VjG5S8rqC"},{"cell_type":"code","source":["# üî¢ Cell 7 ‚Äì Log Processed & Clean Up (with .npy cleanup)\n","import csv\n","import shutil\n","\n","def is_already_processed(song_name):\n","    if not os.path.exists(LOG_PATH):\n","        return False\n","    with open(LOG_PATH, \"r\") as f:\n","        return song_name in f.read()\n","\n","def mark_as_processed(song_name):\n","    with open(LOG_PATH, \"a\", newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([song_name])\n","\n","def cleanup_files(song_name):\n","    try:\n","        mp3_path = os.path.join(DOWNLOAD_DIR, f\"{song_name}.mp3\")\n","        if os.path.exists(mp3_path):\n","            os.remove(mp3_path)\n","\n","        stem_dir = os.path.join(STEMS_BASE_DIR, song_name)\n","        if os.path.exists(stem_dir):\n","            shutil.rmtree(stem_dir)\n","\n","        for instrument in [\"bass\", \"drums\"]:\n","            for ext in [\"mid\", \"json\"]:\n","                file_path = os.path.join(OUTPUT_DIR, f\"{song_name}_{instrument}.{ext}\")\n","                if os.path.exists(file_path):\n","                    os.remove(file_path)\n","\n","            for npy_file in glob(os.path.join(SPECTRAL_OUTPUT_DIR, f\"{song_name}_{instrument}.npy\")):\n","                os.remove(npy_file)\n","\n","        logging.info(f\"üßπ Cleanup complete for: {song_name}\")\n","\n","    except Exception as e:\n","        logging.error(f\"Cleanup failed for {song_name}: {e}\")"],"metadata":{"id":"wMGj67iSCTDX","executionInfo":{"status":"ok","timestamp":1743275493978,"user_tz":420,"elapsed":2,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"wMGj67iSCTDX","execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["üîé Notes:\n","\n","    ‚úÖ Safe file removal after processing\n","\n","    üßæ Appends to processed_log.csv to avoid reprocessing\n","\n","    üîÅ Works great with batch runs and re-runs"],"metadata":{"id":"tqEaBhoWE1l3"},"id":"tqEaBhoWE1l3"},{"cell_type":"code","source":["# üî¢ Cell 8 ‚Äì Batch Runner (With Logging & Validation)\n","from glob import glob\n","\n","mp3_files = glob(os.path.join(DOWNLOAD_DIR, \"*.mp3\"))\n","logging.info(f\"üéß Found {len(mp3_files)} MP3(s) to process.\")\n","\n","for mp3_path in mp3_files:\n","    song_name = os.path.splitext(os.path.basename(mp3_path))[0]\n","\n","    if is_already_processed(song_name):\n","        logging.info(f\"‚è≠Ô∏è  Skipping (already processed): {song_name}\")\n","        continue\n","\n","    try:\n","        logging.info(f\"üöÄ Starting pipeline for: {song_name}\")\n","\n","        _, stem_dir = separate_stems(mp3_path)\n","        upload_stems_to_training(song_name)\n","\n","        for instrument in [\"bass\", \"drums\"]:\n","            midi_path, json_path = generate_midi_and_groove(stem_dir, song_name, instrument)\n","            if midi_path and json_path:\n","                song_key = f\"{song_name}_{instrument}\"\n","                upload_outputs_to_gcs(midi_path, json_path, song_key, output_bucket)\n","\n","        convert_to_spectral_arrays(song_name)\n","        upload_spectral_arrays(song_name)\n","\n","        mark_as_processed(song_name)\n","        cleanup_files(song_name)\n","\n","        logging.info(f\"‚úÖ Finished: {song_name}\")\n","\n","    except Exception as e:\n","        logging.error(f\"‚ùå Error processing {song_name}: {e}\")"],"metadata":{"id":"7bG1L6vvCXDZ","colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"status":"error","timestamp":1743275494072,"user_tz":420,"elapsed":93,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}},"outputId":"18bee594-f825-4a24-ed7e-fa4a58887a1c"},"id":"7bG1L6vvCXDZ","execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'LOG_PATH' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-84225a5efbdd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msong_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_already_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚è≠Ô∏è  Skipping (already processed): {song_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-b8f270cce5f6>\u001b[0m in \u001b[0;36mis_already_processed\u001b[0;34m(song_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_already_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'LOG_PATH' is not defined"]}]},{"cell_type":"markdown","source":["üîé Final Touches:\n","\n","    Runs all 7 steps in a loop\n","\n","    Skips already processed files\n","\n","    Handles exceptions gracefully\n","\n","    Logs, cleans, uploads, and moves on to the next"],"metadata":{"id":"ceFayTVIFLYU"},"id":"ceFayTVIFLYU"},{"cell_type":"code","source":["# üî¢ Cell 9 ‚Äì Upload Separated Stems to GCS Training Bucket\n","\n","def upload_stems_to_training(song_name):\n","    stem_dir = os.path.join(STEMS_BASE_DIR, song_name)\n","    if not os.path.exists(stem_dir):\n","        print(f\"‚ö†Ô∏è Stem directory not found for: {song_name}\")\n","        return\n","\n","    for file in glob(os.path.join(stem_dir, \"*.wav\")):\n","        blob_name = f\"stems/{song_name}/{os.path.basename(file)}\"\n","        blob = training_bucket.blob(blob_name)\n","        print(f\"‚¨ÜÔ∏è Uploading {blob_name}\")\n","        blob.upload_from_filename(file)\n","\n","    print(f\"‚úÖ All stems uploaded for: {song_name}\")\n"],"metadata":{"id":"7OhDKUpW3s9y","executionInfo":{"status":"aborted","timestamp":1743275494528,"user_tz":420,"elapsed":24705,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"7OhDKUpW3s9y","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["üí¨ QC Notes:\n","\n","    ‚úÖ Works well.\n","\n","    üõ°Ô∏è Consider checking if file already exists on GCS before upload."],"metadata":{"id":"JvOrLoTJ82hV"},"id":"JvOrLoTJ82hV"},{"cell_type":"code","source":["# üî¢ Cell 11 ‚Äì Upload Spectrogram Arrays to GCS\n","\n","def upload_spectral_arrays(song_name):\n","    for file in glob(os.path.join(SPECTRAL_OUTPUT_DIR, f\"{song_name}_*.npy\")):\n","        blob_name = f\"spectral/{os.path.basename(file)}\"\n","        blob = training_bucket.blob(blob_name)\n","        print(f\"üì§ Uploading {blob_name}\")\n","        blob.upload_from_filename(file)\n","    print(f\"‚úÖ Uploaded spectral arrays for: {song_name}\")\n"],"metadata":{"id":"TwhOR12G3-72","executionInfo":{"status":"aborted","timestamp":1743275494530,"user_tz":420,"elapsed":24681,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"TwhOR12G3-72","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# üî¢ Cell 12 ‚Äì Build Spectral Dataset JSON\n","\n","import json\n","import numpy as np\n","import os\n","\n","SPECTRAL_DATA_DIR = \"spectral_arrays\"\n","SPECTRAL_JSON_DIR = \"training_data\"\n","SPECTRAL_JSON_PATH = os.path.join(SPECTRAL_JSON_DIR, \"spectral_dataset.json\")\n","\n","os.makedirs(SPECTRAL_JSON_DIR, exist_ok=True)\n","\n","spectral_data = []\n","\n","for file in os.listdir(SPECTRAL_DATA_DIR):\n","    if file.endswith(\".npy\"):\n","        data_path = os.path.join(SPECTRAL_DATA_DIR, file)\n","        spectrogram = np.load(data_path)\n","\n","        # Flatten spectrogram to 1D\n","        flattened = spectrogram.flatten().tolist()\n","\n","        # Extract label from filename (e.g., onedrop_bass.npy ‚Üí onedrop)\n","        label = file.split(\"_\")[0]\n","\n","        spectral_data.append({\n","            \"label\": label,\n","            \"filename\": file,\n","            \"spectrogram\": flattened\n","        })\n","\n","with open(SPECTRAL_JSON_PATH, \"w\") as f:\n","    json.dump(spectral_data, f)\n","\n","print(f\"‚úÖ Saved spectral dataset JSON ‚Üí {SPECTRAL_JSON_PATH}\")\n"],"metadata":{"id":"o_uTpPs23yph","executionInfo":{"status":"aborted","timestamp":1743275494534,"user_tz":420,"elapsed":2,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"o_uTpPs23yph","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["üí¨ QC Notes:\n","\n","    ‚úÖ Good use of CSV log to avoid reprocessing.\n","\n","    ‚ö†Ô∏è Relies on filename-only logic ‚Äî could use hash or unique ID for robustness.\n","\n","    üßπ Cleanup routine assumes specific file naming conventions; may want more flexibility."],"metadata":{"id":"lqrbyupN9m8b"},"id":"lqrbyupN9m8b"},{"cell_type":"code","source":["# üî¢ Cell 13 ‚Äì Upload Spectral Dataset JSON to GCS\n","\n","def upload_spectral_dataset_manifest():\n","    blob = training_bucket.blob(\"training_data/spectral_dataset.json\")\n","    blob.upload_from_filename(SPECTRAL_JSON_PATH)\n","    print(f\"‚òÅÔ∏è Uploaded spectral_dataset.json to: gs://{TRAINING_BUCKET}/training_data/\")\n","\n","upload_spectral_dataset_manifest()\n"],"metadata":{"id":"dvLrIn8zzxOK","executionInfo":{"status":"aborted","timestamp":1743275494535,"user_tz":420,"elapsed":24635,"user":{"displayName":"Justin Anderson","userId":"17014848548549073962"}}},"id":"dvLrIn8zzxOK","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}